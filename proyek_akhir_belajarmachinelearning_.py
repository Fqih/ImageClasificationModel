# -*- coding: utf-8 -*-
"""Proyek_Akhir_BelajarMachineLearning_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wthmivkvPJvmYsi_4U47uhngky6BEQY5

# Data diri

**Nama : Muhammad Faqih Hakim**

**Alamat : Kabupaten Tangerang**

**Email: mhmdfkih21@gmail.com**

---

**Berikut kriteria submission yang harus Anda penuhi:**


*   Dataset yang dipakai haruslah dataset berikut : rockpaperscissors, atau gunakan link ini pada wget command: https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip.
*   Dataset harus dibagi menjadi train set dan validation set.
*   Ukuran validation set harus 40% dari total dataset (data training memiliki 1314 sampel, dan data validasi sebanyak 874 sampel).
*   Harus mengimplementasikan augmentasi gambar.
*   Menggunakan image data generator.
*   Model harus menggunakan model sequential
*   Pelatihan model tidak melebihi waktu 30 menit.
*   Program dikerjakan pada Google Colaboratory.
* Akurasi dari model minimal 85%.


---

Import Library Yang diButuhkan
"""

import os
import zipfile
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop

"""**Siapkan Dataset**"""

#Mengambil Dataset dari Link Yang Disediakan
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

"""**Ekstrak Datsaset serta mendefinisikan nama direktori untuk data train dan data validation.**"""

local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()
dir = '/tmp/rockpaperscissors/rps-cv-images'
train_dir = '/tmp/rockpaperscissors/train'
validation_dir = '/tmp/rockpaperscissors/validation'

"""**Implementasi augmentasi gambar**"""

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    shear_range=0.2,
    horizontal_flip=True,
    fill_mode='wrap',
    validation_split=0.4
)

train_generator = train_datagen.flow_from_directory(
    dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='categorical',
    subset='validation'
)

"""**Membuat Model**"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

"""Cek Struktur Model"""

model.summary()

"""Implementasikan Fungsi Callback"""

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if (logs.get('accuracy') >= .95 and logs.get('val_accuracy') >= .95):
            print("\nPelatihan harus dihentikan karena Sudah mencapai target yang diinginkan")
            self.model.stop_training = True

callbacks = myCallback()

"""**Compaile Model**"""

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""**Latih**"""

hist = model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=20,
    validation_data=validation_generator,
    validation_steps=5,
    verbose=2,
    callbacks=[callbacks]
)

"""**Pelatihan model tidak melebihi 30 menit, hanya sekitar 24 menit**"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
    path = fn
    img = image.load_img(path, target_size=(150, 150))
    imgplot = plt.imshow(img)
    plt.show()

    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)

    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)
    predicted_class = np.argmax(classes, axis=1)[0]

    if predicted_class == 0:
        print(f'{fn} adalah gambar Kertas')
    elif predicted_class == 1:
        print(f'{fn} adalah gambar Batu')
    else:
        print(f'{fn} adalah gambar Gunting')

"""Plot Akurasi dan Plot Validasi"""

plt.plot(hist.history['accuracy'])
plt.plot(hist.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy dan Validasi')
plt.xlabel('Jumlah Epoch')
plt.legend(['Train'], loc='lower right')
plt.show()